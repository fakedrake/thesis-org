\dictum[S. Beckett -- Waiting for Godot (Estragon)]{What do we do now,
now that we are happy?}

\begin{summary}
\item Summary of FluiDB concepts.
\item Future work.
\end{summary}


In this thesis we covered the important and interesting aspects of
FluiDB. Implementing the system itself involved much work that is not
covered in this thesis to avoid flooding the reader with details that
might remove focus from the important aspects of the system. To name a
few we implemented a pretty printing library, a query decorrelation
algorithm, a set of tools for debugging and tracing backtracking
algorithms, etc.

In the introduction we discussed some examples where data layout can
radically adapt to the workload by making use of reversible operations
and integrating a garbage collector into the planner. In the
background chapter, we further introduced the relational database
model and provided an overview of the various stages of query
processing. We focus on two subfields of database research that are of
particular relevance to FluiDB: intermediate result recycling, and
code generation for in-memory databases.

The first non-introductory chapter (chapter
\ref{chapter:fluidb_logical_planning}) goes in depth about the
semantics of reversible operations and how they, along with possible
intermediate results for each query form the QDAG. It covers topics
that relate to the construction of the QDAG, the use of the QDAG for
enumerating plans, higher levels of organization of the QDAG n-nodes
into clusters and how those clusters are used by FluiDB to infer
properties of intermediate query results like cardinality and relation
extent using propagators.

Chapter \ref{chapter:physical_planning} on physical planning starts
off by introducing a novel framework for implementing search
algorithms, the \hask{HCntT} monad transformer. Computation expressed
in terms of \hask{HCntT} can dynamically switch between branches of
the backtracking algorithm essentially implementing a weighted
search. The main novelty lies in the implementation of \hask{once}
and \hask{fallback} operations that, to our knowledge, are not
supported by any similar weighted search framework.

Based on \hask{HCntT} we describe the implementation of the physical
planner that lies at the core of FluiDB. The physical planner uses an
\(A^{\star}\)-like algorithm to traverse the QDAG in order to
enumerate query plans. Query plan fragments are interleaved with GC
runs that produce sequences of table deletions when the planner
detects that the storage budget would be exceeded.

The decisions made by the planner are based on computations that
depend on the inventory of materialized relations, namely
variations of cost estimation of intermediate result and intermediate
result materializability. It makes sense to implement computations in
terms of an incremental computation framework as there are major
opportunities for sharing between evaluations. Furthermore, the
performance of these computations is sensitive to the order of
evaluation due to absorbing elements and \(\min\) operations. To solve
these problems we developed \emph{Antisthenis} which was described in
detail in chapter \ref{chapter:antisthenis}.

We wrap up the technical description of FluiDB with chapter
\ref{chapter:execution_engine} that goes in depth about how FluiDB
transpiles physical plans into C++ and what algorithms are used to
implement each operation and their reverse.

Finally, we present some experimental results to demonstrate the
performance characteristics of FluiDB and any system that might
implement similar concepts to it. Particularly, we run the SSB TPC-H
benchmark and show that FluiDB can successfully outperform a similar
system that only does per-query optimization in amortized cost and
even in most per-query cases. We also demonstrate the expected result
that FluiDB's repertoire of heuristics may cause individual queries
planned within the context of a workload to be be less performant than
the same query planned in isolation. We further demonstrate how FluiDB
usually succeeds at making better use of larger storage budgets but
occasionally, like every heuristic based system, will make decisions
that hurt performance.

\section{Future perspectives}

FluiDB steps into a new path towards what we believe to be a
\emph{truly} adaptive storage, and indicates many interesting research
trajectories. There are many interesting tangents to follow and many
places where FluiDB does not take full advantage of the state of the
art in database research.

Starting with the latter, the most important place where FluiDB can do
better is cardinality estimation. As mentioned FluiDB is very naive
w.r.t. to how it estimates sizes. That said the propagator network
structure used to estimate cardinalities can be augmented to propagate
information about selectivity and statistics about each n-node. These
statistics could be collected for every materialized intermediate
relation to enrich the much needed information available during
planning.

Another low hanging fruit that can be exploited is parallelism. All
plans that FluiDB produces are single threaded but there is no
fundamental reason for that to be so. A simple data dependency
analysis could reveal opportunities for parallelism and operators
themselves could be easily replaced with parallel versions. A more
complex but very interesting problem would be how to teach the planner
to take this into account in order to produce plans that aren't just
accidentally parallel, but are designed taking such speedups into
account.

Another important shortcoming of FluiDB as it was implemented is its
complete lack of support for updates. There are heaps of literature to
draw from and many excellent approaches to the problem. It would be
interesting to find out which of these and how they could be applied
to the peculiar case of FluiDB's data model where primary tables are
likely not materialized in memory.

Furthermore, a system based on FluiDB could take advantage of
non-relational operations like table compression, materialization of
indexes, movement of data in a memory hierarchy in order to produce
plans that can better take advantage of the various possibilities
provided by the state of the art in database research.

Finally, a major bottleneck especially for cheap queries, is the
latency of the C++ compiler that can take up to 10 sec to build a
query plan into an executable. The FluiDB code generation make
absolutely no attempt to make life easier for the C++ compiler, making
heavy use of metaprogramming facilities like templates, traits, and
\cpp{constexpr} expressions. There has been a lot of work to mitigate
this problem, in the literature, some good examples of which are
outlined in the background section \ref{sec:transpilation}
