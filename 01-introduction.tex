\dictum[Author]{Something about the beginning of a journey.}

\begin{summary}
\item FluiDB is an in-memory RDBMs optimizes data layout for space
  efficiency w.r.t. the workload
\item The main novelty relates to the introduction of reversible
  relational operations which affords a new perspective on query
  planning and view selection.
\item She materializes all intermediate nodes and deletes garbage
  collects when she runs out of space.
\end{summary}

With the advent of technologies that make access to information
scalable and affordable, the mental and temporal gap between
collection of data and their analysis grows rapidly. At least two of
the biggest players in the the tech industry, Facebook and Google,
base their competitive advantage almost exclusively on vast amounts of
information that they have collected and their capacity for such
collection and processing. In cases like these the layout of the
stored data is independent of the growing number of applications
taking advantage of it.

A mantra in database community used to be that ``storage is cheap''
and while that is true a more complete version of the mantra might be
that ``slow storage is cheap''.

Databases have traditionally been dealing with the tradeoff between
memory and time efficiency within monetary constraints especially with
the use of intermediate result recycling technologies which employ
sophisticated ways of chosing parts of computation to be stored for
reuse. This model has had some impressive results in OLAP
workloads. We adopt a slightly different view of the problem:
executing query plans does not only leave some specific intermediate
results as residue, but rather \emph{transitions the entire storage
  state from one where the result of the query is not materialized to
  one where it is}. Whith such a notion of query planning what new
dimensions open up in the desgn space of a query planner? The creation
of FluiDB is an attempt to study some aspects of this question. In
particular FluiDB is based on the following pillars:

\begin{itemize}
\item Introduce reversible query operations that allow for more
  sophisticated plans based on available materialized views.
\item The planner itself involves a garbage collector that will delete
  materialized views or primary tables that can be materialized from
  the remaining relations.
\item An incremental numeric evaluation system allows the planner to
  efficiently and repeatedly infer the cost of materializing queries
  under a rapidly changing inventory of materialized views.
\item Query execution is based on code generation.
\end{itemize}

These concepts allow FluiDB to dynamically adapt the data layout to
the workload in ways that would not be possible in traditional
intermediate view recycling systems. To make this more concrete let's
look at an example.

Consider the following query over the TPC-H dataset that computes the
average discount per country:

\begin{code}
\begin{sqlcode}
    select      n_name, avg(l_discount)
    from        lineitem, customer, nation, order
    where       l_orderkey = o_orderkey
    and         c_custkey = o_custkey
    and         c_nationkey = n_nationkey
    and         l_shipdate > 10-11-2015
    group by    n_name
  \end{sqlcode}
\end{code}

An optimizer considering this query in isolation would come up with
some plan resembling the following following plan following:

\begin{figure}[H]
  \begin{tikzdiagram}
    \tikzset{
      every node/.style={draw,rectangle, align=center},
      sibling distance=10cm,
      level distance=3cm
    };
    \node{\gamma}
    child {node{\(\Join\)}
      child {node{\(\Join\)}
        child {node{\(\Join\)}
          child {
            node{\(\sigma_{shipdate > 10-11-2015}\)}
            child { node{lineitem}}
          }
          child {node {order}}
        }
        child {node{customer}}
      }
      child {node{nation}}
    };
  \end{tikzdiagram}
  \caption{\label{fig:single_plan}An efficient logical plan for a
    single query.}
\end{figure}

Notice how the selection (\(\sigma_{shipdate > 10-11-2015}\)) is
pushed all the way to the bottom of the tree because it is a cheap
operation (worst case a full scan over the input) and can potentially
shrink the input by a lot rendering the joins higher in the tree much
cheaper.


Consider a workload that repeatedly runs a query generated from the
following template:

\begin{minted}[escapeinside=||,mathescape=true]{sql}
  select      n_name, avg(l_discount)
  from        lineitem, customer, nation, order
  where       l_orderkey = o_orderkey
  and         c_custkey = o_custkey
  and         c_nationkey = n_nationkey
  and         l_shipdate > |\(\mathit{\$\{min\_date\}}\)|
  group by    n_name
\end{minted}


It is clear in this case that it would be beneficial if the workload
is large enough for the cost of
\(\li \Join \ord \Join \cust \Join \nation\) to be amortized
we would like to materialize the large join and only run
\(\gamma \sigma\) for each query attached as show in figure
\ref{fig:multi_plan}.

\begin{figure}[H]
  \begin{tikzdiagram}
    \tikzset{
      every node/.style={draw,rectangle, align=center},
      sibling distance=10cm,
      level distance=3cm
    };
    \node{\gamma}
    child {
      node{\(\sigma_{shipdate > \$\{min\_date\}}\)}
      child {node (mat){\(\Join\)}
        child {node{\(\Join\)}
          child {node{\(\Join\)}
            child { node{lineitem}}
            child { node {order}}
          }
          child {node{customer}}
        }
        child {node{nation}}
      }
    };
    \node[draw=none] (n) [left = of mat] {Keep materialized}
    edge [-stealth] (mat);
  \end{tikzdiagram}
  \caption{\label{fig:multi_plan}An efficient logical plan for a
    template based workload.}
\end{figure}

This shift of focus from per-query optimization to considering the
amortized cost of materialization of expensive relations is already a
tall order for most RDBMSes that feature materialized views. A simple
but effective approach to integrating incremental query
materialization and the optimization processes, was presented in
\cite{perezHistoryawareQueryOptimization}. In their approach they
maintain a \emph{history pool} (a list of all the past queries) that
is used to decide the benefit of materializing a sub-expression, and a
\emph{view pool} that keeps track of the materialized tables at every
moment. Both these sets are taken into account during planning to
produce a plan that will likely minimize the amortized cost of the
workload. After the query is planned the sets are updated. A
limitation of such an approach is that when dealing with relations
like \(\li \Join \ord\) in budget restricted settings, materialized
view storage can quickly become a scarce resource.

There is an opportunity to reduce the effect of this problem by
exploiting another common workload attribute: certain tables are
frequently subsumed by the same intermediate result. In our example
workload \(\li\) is fully subsumed by \(\li \Join \ord\), \(\li \Join
\ord \Join \cust\), and \(\li \Join \ord \Join \cust \Join
\nation\). Similarly \(\ord\), \(\cust\), and \(\nation\) are fully or
partially subsumed by these relations. It seems wasteful to always
keep the rows of all primary tables separately \emph{and} concatenated
in the rows \(\li \Join \ord \Join \cust \Join \nation\).

In particular we can retrieve the rows of \(\li\) by projecting
on the latter relation and deduplicating the resulting rows we can
obtain any of the former. In this -- contrived yet demonstrative --
example a plan taking into account amortized costs could be:

\begin{figure}[H]
\begin{minted}[escapeinside=||,mathescape=true]{trace-lexer.py:TraceLexer -x}
    Query |\(\gamma \sigma_{p_0}(\li \Join \ord \Join \cust \Join \nation)\)| {
      |\(Q_0\)| := Materialize[|\(\li \Join \ord\)|]
      |\(Q_1\)| := Materialize[|\(\cust \Join Q_0\)|]
      |\(Q_2\)| := Materialize[|\(\nation \Join Q_1\)|]
      # Not enough space to continue. Delete relations that we can rebuild.
      GC {
        Delete[|\(\li\)|]
        Delete[|\(Q_0\)|]
      }
      |\(Q_3\)| := Materialize[|\(\sigma_{p_0} Q_2\)|]
      |\(Q_4\)| := Materialize[|\(\gamma Q_3\)|]
    }
    Query |\(\gamma \sigma_{p_1}(\li \Join \ord \Join \cust \Join \nation)\)| {
      GC {
        Delete[|\(Q_1\)|]
      }
      |\(Q_5\)| := Materialize[|\(\sigma_{p_1} Q_2\)|]
      |\(Q_6\)| := Materialize[|\(\gamma Q_5\)|]
    }
    Query |\(\gamma \sigma_{p_2}(\li \Join \ord \Join \cust \Join \nation)\)| {
       GC {
        Delete[|\(\cust\)|]
       }
      |\(Q_7\)| := Materialize[|\(\sigma_{p_2} Q_2\)|]
      |\(Q_8\)| := Materialize[|\(\gamma Q_7\)|]
    }
    ...
    # Since the large join has all the columns of \li we should be able
    # to create it by simply getting slicing and deduplicating
    Query |\(\li\)| {
      |\(\li\)| := Materialize[|\(uniq\{\pi_{cols(\li)} Q_2\}\)|]
    }
\end{minted}
  \caption{\label{fig:amortized_plan}A sequence of plans optimizing
    the workload amortized cost and involving reverse
    operations. These queries are the same save for the predicate
    \(p_i\) selecting \(\li\)}
\end{figure}

By incorporating reverse relational operations where possible FluiDB
can indeed generate workload plans similar to the one described.

The solution we experiment with by implementing FluiDB resembles the
solution provided in \cite{gouSupSearchEfficient2006} by Gou et.al for
multi-quer. In their work they embed aggregations \sql{group by x1,
  .., xk} into the \(\subseteq\)-lattice that arises from the powerset
\(P(\{x_1, ..., x_k\})\). Thereby they encode the fact that \sql{group
  by A, B, C} is subsumed, or can be computed by, either of \sql{group
  by A, B}, \sql{group by A, C} or \sql{group by B, C}. Once the
lattice is constructed a variant of the \(A^{\star}\) path finding is
used algorithm to search for the optimal aggregation plan. However
they make no attempt to recycle tables, ie. garbage collect tables,
whose data can be found in other relations, and narrows it's attention
to aggregations.

From the aforementioned work we keep the basic notion of using a graph
to represent relationships between queries and to derive the benefit
of materializing a relation. We also use path finding techniques in
that graph to create plans. However we introduce a more complex and
ad-hoc hierarchy of relations to account for subsumptions the entire
relational algebra, rather than just aggregations. That is very
similar to AND-OR dags as found in
\cite{mistryMaterializedViewSelection2001}.  The relations we express
in that graph are bidirectional, so rather than only finding paths
towards the goal and deleting relations when they are no longer needed
via GC plan fragments. We simultaneously plan for moving towards the
goal query and performing "backwards" operations to enrich the space
of possible plans. We clarify this with an example which demonstrates
a slightly simplified version of our system's functionality.

In figure \ref{fig:intro_selectexample} we provide representation of a
subsumption graph that our RDBMS might create after witnessing
selections on \(\li\). For brevity let \(p:=shipdate > 10-11-2015\),
\(q:=quantity < 24\) and \(r:=discount < .06\). The RDBMS has
encountered \(\sigma_{p}(\li)\), \(\sigma_{q}(\li)\) and
\(\sigma_{q} \sigma_{r} (\li)\). For the purposes of this example we
assume that according to the workload the planner has determined that
the priority in terms of usefulness of each qury involved is in
descending order of usefulness:

\begin{itemize}
\item \(\sigma_q \li\)
\item \(\sigma_{p \land r} \li\)
\item \(\sigma_p \li\)
\item \(\sigma_{\neg p} \li\)
\item[ \( \ldots \)]
\item \(\li\)
\end{itemize}


\begin{figure}[H]
  \begin{tikzdiagram}
    \tikzset{
      grow=up,
      sibling distance=10cm,
      level distance=3cm,
      every node/.style={draw},
      mat/.style={fill=gray!30}
    };

    \newcommand{\n}[1]{node {\(#1\)}}
    \newcommand{\bn}[1]{node[mat] {\(#1\)}}

    \node {\(\li\)} % \li
    child { \bn{\sigma_{q}(\li)}} % σ_q
    child { \bn{\sigma_{\neg q}(\li)}} % σ_nq
    child { \n{\sigma_{\neg p}(\li)}}  % σ_np
    child {
      \n{\sigma_{p}(\li)} % σ_p
      child {\n{\sigma_{p \land r}(\li)} } % σ_pq
      child {\n{\sigma_{p \land \neg r}(\li) }} % σ_rpq
    } ;
\end{tikzdiagram}
\caption{\label{fig:intro_selectexample}The materialized relations are
  marked with grey. Assuming the absense of null values and assuming
  set semantics \(\li = \sigma_p \li \cup \sigma_{\neg p} \li\),
  FluiDB can find a plan to generate any of the relations in the graph
  from \(\sigma_p \li\) and \(\sigma_{\neg p} \li\).  }
\end{figure}

The query that we are planning is
\(\sigma_{quantity < 24} \sigma_{discount < .06} (\li)\), which is
denoted in the figure as \(\sigma_{q \land r}(\li)\). Our total size
budget is 2.5.

Following the edges in the graph, to plan \(\sigma_{q \land r}(\li)\)
we need \(\sigma_{q}(\li)\) and for that we need \(\li\) and is least
beneficial. So first we plan the union

\[
  \sigma_{\neg p}(\li) \cup \sigma_{p}(\li) \rightarrow \li
\]

Then we need \(\sigma_{q}(\li)\) but we are now using 2 units of space
and adding .6 more would exceed our space budget of 2.5. \(\li\) is
the least beneficial of our materialized views but it is required for
our next step, ie. creating \(\sigma_{q}(\li)\) . \(\sigma_{\neg
p}(\li)\) is deleted since it's derivable from \(\li\). Then
\(\sigma_{q}(\li)\) is created and now we are using 2.1 units of
space.

\[
  \li \rightarrow \sigma_{q}(\li)
\]

Finally we need to create the final relation \(\sigma_{q \land
  r}(\li)\) . However it's space requirement is .5 and we we would
be exceeding our budget. We can't delete \(\li\) even though it
is our least beneficial table because we would have no way of
recreating it.

Here we have two options. One is to delete \(\sigma_{\neg
  p}(\li)\), our most benefit al table. The other, which is the one
that the system should opt for, is to backtrack. When we created
\(\sigma_{q}(\li)\), instead we create both
\(\sigma_{q}(\li)\) and \(\sigma_{\neg q}(\li)\).

\[
  \li \rightarrow \{\sigma_{q}(\li), \sigma_{\neg q}(\li)\}
\]

Once both those tables are materialized we can safely delete
\(\li\). Now our space usage is 1.1 and we can safely

\[
  \sigma_{q}(\li) \rightarrow \sigma_{q \land r} (\li)
\]

Which is the requested query and, in summary, the final can be
represented as:


\begin{figure}[H]
\begin{minted}[escapeinside=||,mathescape=true]{trace-lexer.py:TraceLexer -x}
    Inventory {
      |\(Q_0\)| := |\(\sigma_{\neg p}(\li)\)|
      |\(Q_1\)| := |\(\sigma_{p}(\li)\)|
      ...
    }
    Query |\(\sigma_{q \land r} \mathit{\li}\)| {
      |\(\li\)| := Materialize[|\(Q_0 \cup  Q_1\)|]
      GC { Delete[|\(Q_0\)|] }
      |\(Q_2\)|,|\(Q_3\)| := Materialize[|\(\{\sigma_{q}(\li), \sigma_{\neg q}(\li)\}\)|]
      GC { Delete[|\(\li\)|] }
      |\(Q_4\)| := Materialize[|\(\sigma_{r} Q_2\)|]
    }
\end{minted}
  \caption{\label{fig:reverse_operations}A sequence of plans optimizing
    the workload amortized cost and involving reverse operations.}
\end{figure}

This radical approiach to adaptation of data to the workload is
particularly useful in contexts where (fast) memory is scarce compared
to the data, particularly in-memory databases. In that vain we lean
heavily on executing plan by transpiling the plan to C++ code.

This thesis describes in detail how we implemented FluiDB, a system
targeted at performing this kind of reasoning to planning and
executing queries. In chapter \ref{chapter:background} we provide a
brief overview of the state of the art and common practices that
pretain to query processing; in chapter
\ref{chapter:fluidb_logical_planning} we describe how queries are
processed and stored at a logical level; in chapter
\ref{chapter:physical_planning} we describe how FluiDB performs
planning and garbage collection to come up with a concrete physical
plan for each query; in chapter \ref{chapter:antisthenis} we go over
an incremental evaluation system we built to facilitate the
requirements of the physical planner; in chapter
\ref{chapter:execution_engine} we go over the algorithms and
particular techniques that FluiDB employs to transpile the physical
plan into C++ code; finally at chapter \ref{chapter:evaluation} we
describe our exprimental evaluation of FluiDB on the benchmark
SSB-TPC-H. We present a conclusion and some future directions in the
final chapter \ref{chapter:conclusion}
