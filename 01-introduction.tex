\dictum[G. W. F. Hegel -- Phenomenology of Spirit]{In [dialectical]
movement, consciousness experiences the emergence of individuality in
the unchangeable, and of the unchangeable in individuality.}

\begin{summary}
\item FluiDB is an in-memory RDBMSes optimizes data layout for space
  efficiency w.r.t. the workload
\item The main novelty relates to the introduction of reversible
  relational operations which affords a new perspective on query
  planning and view selection.
\item FluiDB materializes all intermediate results and deletes garbage
  collects when she runs out of space.
\end{summary}

With the advent of technologies that make access to information
scalable and affordable, the mental and temporal gap between
collection of data and their analysis grows rapidly. At least two of
the biggest players in the tech industry, Facebook and Google,
base their competitive advantage almost exclusively on vast amounts of
information that they have collected and their capacity for such
collection and processing. In cases like these, the layout of the
stored data is independent of the growing number of applications
taking advantage of it.

A mantra in the database community used to be that ``storage is cheap''
and while that is true a more complete version of the mantra might be
that ``slow storage is cheap''.

Databases have traditionally been dealing with the trade-off between
memory and time efficiency within monetary constraints, especially with
the use of intermediate result recycling technologies which employ
sophisticated ways of choosing parts of computation to be stored for
reuse. This model has had some impressive results in OLAP
workloads. We adopt a slightly different view of the problem:
executing query plans does not only leave some specific intermediate
results as residue, but rather \emph{transitions the entire storage
  state from one where the result of the query is not materialized to
  one where it is}. With such a notion of query planning what new
dimensions open up in the design space of a query planner? The creation
of FluiDB is an attempt to study some aspects of this question. In
particular FluiDB is based on the following pillars:

\begin{itemize}
\item Introduce reversible query operations that allow for more
  sophisticated plans based on available materialized views.
\item The planner itself involves a garbage collector that will delete
  materialized views or primary tables that can be materialized from
  the remaining relations.
\item An incremental numeric evaluation system allows the planner to
  efficiently and repeatedly infer the cost of materializing queries
  under a rapidly changing inventory of materialized views.
\item Query execution is based on code generation.
\end{itemize}

These concepts allow FluiDB to dynamically adapt the data layout to
the workload in ways that would not be possible in traditional
intermediate view recycling systems. To make this more concrete let's
look at an example.

Consider the following query over the TPC-H dataset that computes the
average discount per country:

\begin{code}
\begin{sqlcode}
    select      n_name, avg(l_discount)
    from        lineitem, customer, nation, order
    where       l_orderkey = o_orderkey
    and         c_custkey = o_custkey
    and         c_nationkey = n_nationkey
    and         l_shipdate > 10-11-2015
    group by    n_name
  \end{sqlcode}
\end{code}

An optimizer considering this query in isolation would come up with
some plan resembling the following following plan following:

\begin{figure}[H]
  \begin{tikzdiagram}
    \tikzset{
      every node/.style={draw,rectangle, align=center},
      sibling distance=10cm,
      level distance=3cm
    };
    \node{\gamma}
    child {node{\(\Join\)}
      child {node{\(\Join\)}
        child {node{\(\Join\)}
          child {
            node{\(\sigma_{\mathit{l\_shipdate} > 10-11-2015}\)}
            child { node{lineitem}}
          }
          child {node {nation}}
        }
        child {node{customer}}
      }
      child {node{order}}
    };
  \end{tikzdiagram}
  \caption{\label{fig:single_plan}An efficient logical plan for a
    single query.}
\end{figure}

Notice how the selection (\(\sigma_{\mathit(l\_shipdate) > 10-11-2015}\)) is
pushed all the way to the bottom of the tree because it is a cheap
operation (worst case a full scan over the input) and can potentially
shrink the input by a lot rendering the joins higher in the tree much
cheaper.


Consider a workload that repeatedly runs a query generated from the
following template:

\begin{minted}[escapeinside=||,mathescape=true]{sql}
  select      n_name, avg(l_discount)
  from        lineitem, customer, nation, order
  where       l_orderkey = o_orderkey
  and         c_custkey = o_custkey
  and         c_nationkey = n_nationkey
  and         l_shipdate > |\(\mathit{\$\{min\_date\}}\)|
  group by    n_name
\end{minted}


It is clear in this case that it would be beneficial if the workload
is large enough for the cost of
\(\li \Join \ord \Join \cust \Join \nation\) to be amortized
we would like to materialize the large join and only run
\(\gamma \sigma\) for each query attached as show in figure
\ref{fig:multi_plan}.

\begin{figure}[H]
  \begin{tikzdiagram}
    \tikzset{
      every node/.style={draw,rectangle, align=center},
      sibling distance=10cm,
      level distance=3cm
    };
    \node{\gamma}
    child {
      node{\(\sigma_{shipdate > \$\{min\_date\}}\)}
      child {node (mat){\(\Join\)}
        child {node{\(\Join\)}
          child {node{\(\Join\)}
            child { node{lineitem}}
            child { node {nation}}
          }
          child {node{customer}}
        }
        child {node{order}}
      }
    };
    \node[draw=none] (n) [left = of mat] {Keep materialized}
    edge [-stealth] (mat);
  \end{tikzdiagram}
  \caption{\label{fig:multi_plan}An efficient logical plan for a
    template based workload. The relational algebra operators used are:
    \(\gamma\) for aggregations. \(\sigma\) for selection, and \(\Join\) for joins.}
\end{figure}

This shift of focus from per-query optimization to considering the
amortized cost of materialization of expensive relations is already a
tall order for most RDBMSes that feature materialized views. A simple
but effective approach to integrating incremental query
materialization and the optimization processes, was presented in
\cite{perezHistoryawareQueryOptimization}. In their approach they
maintain a \emph{history pool} (a list of all the past queries) that
is used to decide the benefit of materializing a sub-expression, and a
\emph{view pool} that keeps track of the materialized tables at every
moment. Both these sets are taken into account during planning to
produce a plan that will likely minimize the amortized cost of the
workload. After each query is planned the sets are updated. A
limitation of such an approach is that when dealing with relations
like \(\li \Join \ord\) in budget restricted settings, materialized
view storage can quickly become a scarce resource.

There is an opportunity to reduce the effect of this problem by
exploiting another common workload attribute: certain tables are
frequently subsumed by the same intermediate result. In our example
workload \(\li\) is fully subsumed by \(\li \Join \ord\), \(\li \Join
\ord \Join \cust\), and \(\li \Join \ord \Join \cust \Join
\nation\). Similarly \(\ord\), \(\cust\), and \(\nation\) are fully or
partially subsumed by similar relations. It seems wasteful to always
keep the rows of all primary tables separately \emph{and} concatenated
in the rows of \(\li \Join \ord \Join \cust \Join \nation\).

In particular we can retrieve the rows of \(\li\) by projecting
on the latter relation and deduplicating the resulting rows we can
obtain any of the former. In this -- contrived yet demonstrative --
example a plan taking into account amortized costs could be:

\begin{figure}[H]
\begin{minted}[escapeinside=||,mathescape=true]{trace-lexer.py:TraceLexer -x}
    Query |\(\gamma \sigma_{p_0}(\li \Join \ord \Join \cust \Join \nation)\)| {
      |\(Q_0\)| := Materialize[|\(\li \Join \ord\)|]
      |\(Q_1\)| := Materialize[|\(\cust \Join Q_0\)|]
      |\(Q_2\)| := Materialize[|\(\nation \Join Q_1\)|]
      # Not enough space to continue. Delete relations that we can rebuild.
      GC {
        Delete[|\(\li\)|]
        Delete[|\(Q_0\)|]
      }
      |\(Q_3\)| := Materialize[|\(\sigma_{p_0} Q_2\)|]
      |\(Q_4\)| := Materialize[|\(\gamma Q_3\)|]
    }
    Query |\(\gamma \sigma_{p_1}(\li \Join \ord \Join \cust \Join \nation)\)| {
      GC {
        Delete[|\(Q_1\)|]
      }
      |\(Q_5\)| := Materialize[|\(\sigma_{p_1} Q_2\)|]
      |\(Q_6\)| := Materialize[|\(\gamma Q_5\)|]
    }
    Query |\(\gamma \sigma_{p_2}(\li \Join \ord \Join \cust \Join \nation)\)| {
       GC {
        Delete[|\(\cust\)|]
       }
      |\(Q_7\)| := Materialize[|\(\sigma_{p_2} Q_2\)|]
      |\(Q_8\)| := Materialize[|\(\gamma Q_7\)|]
    }
    ...
    # Since the large join has all the columns of \li we should be able
    # to create it by simply getting slicing and deduplicating
    Query |\(\li\)| {
      |\(\li\)| := Materialize[|\(uniq\{\pi_{cols(\li)} Q_2\}\)|]
    }
\end{minted}
  \caption{\label{fig:amortized_plan}A sequence of plans optimizing
    the workload amortized cost and involving reverse
    operations. These queries are the same save for the predicate
    \(p_i\) selecting \(\li\)}
\end{figure}

By incorporating reverse relational operations where possible FluiDB
can indeed generate workload plans similar to the one described.

The solution we experiment with by implementing FluiDB resembles the
solution provided in \cite{gouSupSearchEfficient2006} by Gou et.al for
multi-query optimization (MQO). In their work they embed aggregations \sql{group by x1,
..., xk} into the \(\subseteq\)-lattice that arises from the power set
\(P(\{x_1, ..., x_k\})\). Thereby they encode the fact that \sql{group
  by A, B, C} is subsumed, or can be computed from of:
\begin{itemize}
\item \sql{group by A, B},
 \item \sql{group by A, C}
 \item \sql{group by B, C}.
 \item[...]
\end{itemize}

Once the lattice is constructed a variant of the \(A^{\star}\) path finding is
used algorithm to search for the optimal aggregation plan. However
they make no attempt to recycle tables, i.e.. garbage collect tables,
whose data can be found in other relations, and narrows it's attention
to aggregations.

From the aforementioned work we keep the basic notion of using a graph
to represent relationships between queries and to derive the benefit
of materializing a relation. We also use path finding techniques in
that graph to create plans. However we introduce a more complex and
ad-hoc hierarchy of relations to account for subsumptions in the entire
relational algebra, rather than just aggregations that is very
similar to AND-OR dags as found in
\cite{mistryMaterializedViewSelection2001}.  The relations we express
in that graph are bidirectional, so rather than only finding paths
towards the goal and deleting relations when they are no longer needed
via GC plan fragments, we simultaneously plan for moving towards the
goal query and performing "backwards" operations to enrich the space
of possible plans. This process will become clear with an example which demonstrates
a slightly simplified version of our system's functionality:

In figure \ref{fig:intro_selectexample} we provide representation of a
subsumption graph that our RDBMS might create after witnessing
selections on \(\li\):
\begin{itemize}
    \item \sql{select * from lineitem where l_quantity < 24}
    \item \sql{select * from lineitem where l_shipdate > 10-11-2015}
    \item \sql{select * from lineitem where l_discount < 0.06}
    \item \sql{select * from lineitem where l_discount < 0.06 and l_shipdate > 10-11-2015}
\end{itemize}

For brevity let \(p:=shipdate > 10-11-2015\),
\(q:=quantity < 24\) and \(r:=discount < .06\). In relational algebraic
representation the queries the RDBMS has
encountered are \(\sigma_{p}(\li)\), \(\sigma_{q}(\li)\) and
\(\sigma_{q} \sigma_{r} (\li)\). For the purposes of this example we
assume that according to the workload, the planner has determined that
the priority in terms of usefulness of each query involved is in
descending order of ``usefulness'':

\begin{table}[H]
  \centering
  \begin{tabular}{ll}
    View & Size \\
    \hline
\(\sigma_q \li\) & 5 \\
\(\sigma_p \li\) & 6 \\
\(\sigma_{\neg p} \li\) & 4 \\
\(\sigma_{p \land r} \li\) & 1 \\
\(\sigma_q \li\) & 6 \\
\(\sigma_{\neg q} \li\) & 5 \\
\(\li\) & 10 \\
  \end{tabular}
  \caption{\label{tab:views_sizes}The of figure \ref{fig:intro_selectexample} annotated with their sizes and  ordered in descending order of ``usefullness'' as determined by the planner.}

\end{table}


\begin{figure}[H]
  \begin{tikzdiagram}
    \tikzset{
      grow=up,
      sibling distance=10cm,
      level distance=3cm,
      every node/.style={draw},
      mat/.style={fill=gray!30}
    };

    \newcommand{\n}[1]{node {\(#1\)}}
    \newcommand{\bn}[1]{node[mat] {\(#1\)}}

    \node {\(\li\)} % \li
    child { \bn{\sigma_{q} \li }} % σ_q
    child { \bn{\sigma_{\neg q} \li}} % σ_nq
    child { \n{\sigma_{\neg p} \li}}  % σ_np
    child {
      \n{\sigma_{p} \li} % σ_p
      child {\n{\sigma_{p \land r} \li} } % σ_pq
      child {\n{\sigma_{p \land \neg r} \li}} % σ_rpq
    } ;\
\end{tikzdiagram}
\caption{\label{fig:intro_selectexample}The currently materialized relations are
  marked with gray. Assuming the absence of null values and assuming
  set semantics \(\li = \sigma_p \li \cup \sigma_{\neg p} \li\),
  FluiDB can find a plan to generate any relation involving \(\li\).. }
\end{figure}

The query that we are planning is \(\sigma_{quantity < 24}
\sigma_{discount < .06} \li\), which is denoted in the figure as
\(\sigma_{p \land r}\li\). Our total size budget is 25. The plan
described is codified in \ref{fig:reverse_operations}.

Following the edges in the graph, to plan \(\sigma_{p \land r}\li\)
we need \(\sigma_{p}\li\) and for that we need \(\li\). So first we plan the union

\[
  \sigma_{\neg q}\li \cup \sigma_{q}\li \rightarrow \li
\]

Then we need \(\sigma_{p}\li\) but we are now using 20 units of space
and adding 6 more would exceed our space budget of 25 units. \(\li\)
is the least beneficial of our materialized views but it is required
for our next step, i.e., creating \(\sigma_{p}\li\), \(\sigma_{\neg
q} \li\) is deleted instead since it is derivable from \(\li\). We can
now create not only \(\sigma_{p}(\li)\), but also \(\sigma_{\neg
p}(\li)\) so we are now using 25 units of space.

\[
  \li \rightarrow \{\sigma_{p}\li, \sigma_{\neg p}\li\}
\]

Finally, we need to create the final relation \(\sigma_{p \land
  r}\li\) . However the available storage is all used up. We can now
  delete \(\li\) because its data is duplicated in the combination if
  \(\sigma_{p}\li\) and \(\sigma_{\neg p}\li\). Once that deletion is
  carried out we can create \(\sigma_{p \land r} \li \) which was the
  requested query.


\begin{figure}[H]
\begin{minted}[escapeinside=||,mathescape=true]{trace-lexer.py:TraceLexer -x}
    Inventory {
      |\(Q_0\)| := |\(\sigma_{\neg q}\li\)|
      |\(Q_1\)| := |\(\sigma_{q}\li\)|
    }

    # Budget: 25, used: 10
    Query |\(\sigma_{q \land r} \mathit{\li}\)| {
      |\(\li\)| := Materialize[|\(Q_0 \cup  Q_1\)|]
      # used: 20; we need 26 to proceed...
      GC { Delete[|\(Q_0\)|] }
      # used: 15 we can now materialize both
      |\(Q_2\)|,|\(Q_3\)| := Materialize[|\(\{\sigma_{p}\li, \sigma_{\neg p}\li\}\)|]
      # used: 25; we can delete lineitem now
      GC { Delete[|\(\li\)|] }
      # used: 15; we can now materialize the requested
      |\(Q_4\)| := Materialize[|\(\sigma_{r} Q_2\)|]
    }
\end{minted}
  \caption{\label{fig:reverse_operations}A sequence of plans optimizing
    the workload amortized cost and involving reverse operations.}
\end{figure}

This radical approach to adaptation of data to the workload is
particularly useful in contexts where (fast) memory is scarce compared
to the data, particularly in-memory databases. In that vain we lean
heavily on executing plans by transpiling the plan to C++ code.


  The overall system is comprised of three internal their
  interlocation being described in diagram \ref{fig:architecture}. An
  SQL query is initially parsed and passed to the \emph{Graph Builder}
  which correlates it and its possible subqueries to historical
  queries using the \emph{QNF processor} which evaluates the
  equivalence between subplans. This way the \emph{Relational Algebra
    (RA) Graph} is populated with nodes corresponding to relations
  connected by often bidirectional operators.

  The next level in the pipeline is the planner, which traverses the
  graph using an \(A^{\star}\) inspired branch and bound algorithm in
  order to come up with a plan that a) efficiently computes the
  requested query and b) optimizes the data layout to provide
  opportunity for efficient future plans. Pruning of the search space
  is assisted by \emph{Antisthenis}, an incremental framework
  optimized a) for calculating the expected cost of materializing a
  relation without actually planning for it as well as b) calculating
  whether a relation is materializable at all given the currently
  materialized relations. The plan generated has the form of a
  sequence of operators and relation deletions which are finally
  translated to C++ and compiled with an off-the-shelf compiler.

  \begin{figure}[H]
  \begin{tikzdiagram}
    \tikzset{db/.style={cylinder,draw,shape border rotate=90,aspect=.3}};
    \tikzset{sys/.style={rectangle,draw}};
    \tikzset{outer/.style={cloud,draw,aspect=3}};

    \node[outer] (query) {Query stream};
    \node[sys] (graph_builder) [below = of query] {Graph Builder};

    \node[sys] (qnf) [left = of graph_builder] {QNF processor};

    \node[db] (bqg) [right = of graph_builder] {RA Graph};
    \node[sys] (planner) [below = of graph_builder] {Planner};

    \node[sys] (antisthenis) [left = of planner] {Antisthenis};
    \node[sys] (codegen) [below = of planner] {C++ generation};
    \node[sys] (cc) [below = of codegen] {C++ Compiler};
    \node[outer] (hw) [below = of cc] {CPU/Filesystem};

    \draw[->] (query) -> (graph_builder) -> (planner) -> (codegen) -> (cc) -> (hw);
    \draw[<->] (planner) -> (antisthenis);
    \draw[<->] (graph_builder) -> (qnf);
    \draw[<->] (graph_builder) -> (bqg);
  \end{tikzdiagram}
  \caption{\label{fig:architecture}The system architecture}
\end{figure}

\begin{corrected}{Thesis contributions}

In this thesis we highlight the following contributions:

\begin{itemize}
\item We introduce the concept of reversible relational
  operators. FluiDB is built around leveraging this idea to adapt the
  layout of primary data to the workload. This allows FluiDB to
  efficiently answer complex queries and share computation between
  different queries with minimal memory footprint. It is discussed in
  detail in chapter \ref{chapter:fluidb_logical_planning}.
\item We present a monadic framework for branch and bound
  search. While branch and bound is an algorithm common in rewrite
  systems it has not been implemented based on a monad. This approach
  affords flexibility and composability to easily implement and tweak
  complex heuristics and search space pruning techniques. The
  \hask{HCntT} monad transformer that captures this is discuessed in
  chapter~\ref{chapter:physical_planning}.
\item We introduce an incremental computation system that focuses on
  incrementally computing the cost estimation of logical plans for
  relational queries. There is little work on incremental cost
  estimation functions and none that applies to either recursive
  (non-DAG) operator graphs or that takes into account materialized
  intermediate results. To make FluiDB's optimization tractable we
  introduce a novel, highly specialized, incremental computation
  framework we call Antisthenis. Antisthenis is discussed in detail in
  chapter \ref{chapter:antisthenis}.
\end{itemize}

  \begin{comment}
\begin{itemize}
\item We provide an overview of the literature regarding intermediate
  result recycling.
\item We describe a framework and a case study for a novel approach of
  unifying query planning and intermediate result management.
\item We introduce reversible relational operators and how they can be
  used to create effective plans in memory constrained environments,
  effectively unifying the query planning and intermediate result
  recycling mechanisms.
\item We introduce a novel variant of a branch and bound algorithm
  used for planning relational queries.
\item We introduce Antisthenis, a novel approach to incremental
  computation used for the needs of query planning that aggressively
  takes advantage of the particular properties of the computations
  involved in plan cost estimation and relation materialisability.
\item We describe a code generation framework to support the operation
  of FluiDB.
\item We provide experimental evaluation of how all these parts fit
  together to compose FluiDB, particularly in the context of a star
  schema based benchmark.
\end{itemize}
\end{comment}
\end{corrected}

This thesis describes in detail how we implemented FluiDB, a system
targeted at performing this kind of reasoning for planning and
executing queries. In chapter \ref{chapter:background} we provide a
brief overview of the state of the art and common practices that
pertain to query processing; in chapter
\ref{chapter:fluidb_logical_planning} we describe how queries are
processed and stored at a logical level and various methods we employ for
overcoming the challenges of assembling queries in a graph; in chapter
\ref{chapter:physical_planning} we describe how FluiDB performs
planning and garbage collection to come up with a concrete physical
plan for each query; in chapter \ref{chapter:antisthenis} we go over
an incremental evaluation system we built to facilitate the
requirements of the physical planner; in chapter
\ref{chapter:execution_engine} we go over the algorithms and
particular techniques that FluiDB employs to transpile the physical
plan into C++ code; finally at chapter \ref{chapter:evaluation} we
describe our experimental evaluation of FluiDB on the benchmark
SSB-TPC-H. We present a conclusion and some future directions in the
final chapter \ref{chapter:conclusion}
